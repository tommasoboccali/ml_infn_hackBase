{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cardiac-convert",
   "metadata": {
    "id": "cardiac-convert"
   },
   "source": [
    "# Numpy, Pyplot, Pandas and CERN Open Data\n",
    "\n",
    "In this module we will discuss some basics on numpy, pyplot and pandas using datasets from the CERN Open Data service as examples. \n",
    "Some fluency with all of these packages is expected, however it seems useful to provide a common code base for some basic operations that will be necessary for the next tutorials more specific on *Machine Learning*.\n",
    "\n",
    "For additional information, some useful reference is provided below.\n",
    "\n",
    " * Python: https://www.learnpython.org/, https://www.w3schools.com/python/\n",
    " * Pip: https://realpython.com/what-is-pip/ \n",
    " * Numpy: https://numpy.org/doc/stable/user/quickstart.html\n",
    " * Matplotlib: https://realpython.com/python-matplotlib-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-inspection",
   "metadata": {
    "id": "romance-inspection"
   },
   "source": [
    "## Loading data with pandas\n",
    "The first very common operation when dealing with data is to load them to memory. \n",
    "If the dataset is sufficiently small to be completely contained in the RAM of the processor, the whole dataset can be imported into a *pandas DataFrame*, a tabular data structure with efficient and simplified access to the data. \n",
    "In case of larger datasets, one should choose among several different possibilities:\n",
    " * loading chunks of the dataset into panda dataframe for iterative processing;\n",
    " * preprocess the dataset and store it in binary format for accessing it more efficiently in distributed architectures;\n",
    " * switching to a computer with more memory. \n",
    "\n",
    "To present an example, we will consider a dataset of muon pairs collected by CMS in 2011 and released to the general public through the CERN Open Data portal: https://opendata.cern.ch/record/5202\n",
    "\n",
    "Muons are elementary particles, with similar properties to electrons, but with a mass ~207 times larger. Because of their properties, muons are highly penetrating particles and are the only charged particles that can traverse the thick calorimeters designed to adsorb the whole energy of electrons, photons and hadrons. This provides a very effective identification technique, that allows to collect highly pure samples of muons and study, for example, their production mechanism. \n",
    "In this sample we find muon pairs, composed of a positive and a negative muon ($\\mu^+ \\mu^-$).\n",
    "\n",
    "Muon pairs can be produced in proton proton collisions through electromagnetic (and more rarely weak) interactions. Some hadron can decay through electromagnetic interaction and originate a muon pair. If muon pairs are originated in the decay of a heavier particle $h \\to \\mu^+ \\mu^-$, then their invariant mass \n",
    "$$\n",
    " M = \\sqrt{(E_1\\ c^2 + E_2\\ c^2)^2 - (p_{x1}c + p_{x2}c)^2  - (p_{y1}c + p_{y2}c)^2  - (p_{z1}c + p_{z2}c)^2}\n",
    "$$\n",
    "will be the same as for their parent particle. \n",
    "In the formula,\n",
    " * $E_1$ and $E_2$ are the energy of the two muons\n",
    " * $(p_{x1}, p_{y1}, p_{y1})$, $(p_{x2}, p_{y2}, p_{y2})$ are the vectors describing the momentum of the two muons,\n",
    " * $c$ is the speed of light\n",
    "\n",
    "Let's load the dataset from the CERN Open Data into a pandas dataframe. \n",
    "From the description web page, we observe that the dataset is made available in csv (*Comma separated values*) format, we can therefore use the pandas function `read_csv` to import the dataset into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-conversion",
   "metadata": {
    "id": "optional-conversion"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv (\"https://opendata.cern.ch/record/5202/files/Dimuon_SingleMu.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-dancing",
   "metadata": {
    "id": "developmental-dancing"
   },
   "source": [
    "Once imported, the dataset can be investgated with the function `describe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-trash",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "progressive-trash",
    "outputId": "b7d7b9e1-2c4d-401b-8d75-d38a68d7cdfe"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-crazy",
   "metadata": {
    "id": "burning-crazy"
   },
   "source": [
    "A single column can be extracted with the square-bracket operator (*getitem*) as a `pandas Series`, representing a single column composed of an index the associated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-assist",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "domestic-assist",
    "outputId": "9869f925-cfd1-48de-b35e-e10e0ea6a24f"
   },
   "outputs": [],
   "source": [
    "invariant_mass = df['M']\n",
    "print (invariant_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-sandwich",
   "metadata": {
    "id": "occupied-sandwich"
   },
   "source": [
    "Values can be extracted into a  `numpy` array using the `values` keyword. Simlarly, `index` allow to access the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-mailman",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "satisfied-mailman",
    "outputId": "381560a6-cc8f-4fec-b3ad-beaf46efbe5b"
   },
   "outputs": [],
   "source": [
    "m = invariant_mass.values\n",
    "idx = invariant_mass.index\n",
    "\n",
    "print (\"Mass values:\", m)\n",
    "print (\"Indices:\", idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-thesis",
   "metadata": {
    "id": "antique-thesis"
   },
   "source": [
    "## Plotting histograms\n",
    "The content of the `numpy array`, or the `pandas Series` directly, can be used to fill an histogram and get information on the distribution of the selected quantities.\n",
    "\n",
    "Many `Python` packages exist to draw plots and histograms. The most common and widely applied is `pyplot` made available within the `matplotlib` bundle. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-sound",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "mobile-sound",
    "outputId": "80822d62-63d1-4943-a614-b2b5a377951b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist (invariant_mass)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-transsexual",
   "metadata": {
    "id": "functional-transsexual"
   },
   "source": [
    "We obtained this histogram very easily, but unfortunately the result is not particularly readable. First of all we should refine the binning scheme, we need more bins and we can happily exclude everything beyond 150 GeV/c.\n",
    "In order to define the binning scheme we will use the numpy function `linspace` to define the boundaries of the bins. \n",
    "`linspace` produces a series of equidistant values given the lower value, the higher value and the number of values.\n",
    "\n",
    "> **Note!** The number of boundaries, used to define the binning scheme, is the number of bins plus 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-sheffield",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "statutory-sheffield",
    "outputId": "9d16ef42-b2cb-472e-ef21-00108a181e43"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "boundaries = np.linspace(0, 150, 151) # 151 boundaries from 0 to 150 GeV.\n",
    "plt.hist (invariant_mass, bins=boundaries)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-plymouth",
   "metadata": {
    "id": "comfortable-plymouth"
   },
   "source": [
    "Much better! But still the readability is not sufficient. We should include axes labels, maybe a title and possibly a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-reynolds",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "inclusive-reynolds",
    "outputId": "f483e897-1d5e-462f-e016-53169e11acf0"
   },
   "outputs": [],
   "source": [
    "boundaries = np.linspace(0, 150, 151) # 151 boundaries from 0 to 150 GeV.\n",
    "plt.hist (invariant_mass, bins=boundaries, label = \"CMS 2011 data\")\n",
    "plt.title (\"Invariant mass of the muon pairs\")\n",
    "plt.xlabel (\"Dimuon invariant mass [GeV/$c^2$]\")\n",
    "plt.ylabel (\"Number of dimuons\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-settle",
   "metadata": {
    "id": "entire-settle"
   },
   "source": [
    "## Selecting data from a pandas DataFrame with `query`\n",
    "The histogram shown above highlights three regions of interest. One below 5 GeV, one aroung 10 GeV and one around 90 GeV. \n",
    "\n",
    "We can use the function `query` of the pandas dataframe in order to select these data from the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-stanford",
   "metadata": {
    "id": "defined-stanford"
   },
   "outputs": [],
   "source": [
    "lowM = df.query ( \"M < 5\" ) ['M']\n",
    "midM = df.query ( \"M > 8 and M < 13\") ['M']\n",
    "highM = df.query ( \"M > 70 and M < 110\") ['M']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-credits",
   "metadata": {
    "id": "constitutional-credits"
   },
   "source": [
    "We can then superpose to the full histograms, the histograms obtained once these selections are applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-cheese",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "proved-cheese",
    "outputId": "bff2a15b-2543-48dc-d715-ca7f2b6468c8"
   },
   "outputs": [],
   "source": [
    "boundaries = np.linspace(0, 150, 151) # 151 boundaries from 0 to 150 GeV.\n",
    "plt.hist (invariant_mass, bins=boundaries, label = \"CMS 2011 data\")\n",
    "plt.hist (lowM, bins=boundaries, label = \"Low mass region\")\n",
    "plt.hist (midM, bins=boundaries, label = \"Mid mass region\")\n",
    "plt.hist (highM, bins=boundaries, label = \"High mass region\")\n",
    "plt.title (\"Invariant mass of the muon pairs\")\n",
    "plt.xlabel (\"Dimuon invariant mass [GeV/$c^2$]\")\n",
    "plt.ylabel (\"Number of dimuons\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-homeless",
   "metadata": {
    "id": "found-homeless"
   },
   "source": [
    "When superposing histograms it is sometimes useful to show some of them as \"empty\" with only a line identifying the bin content. This can be achieved using the `histtype='step'` keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-hamburg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frank-hamburg",
    "outputId": "818bba28-54d6-408e-9e87-519507b1f4bd"
   },
   "outputs": [],
   "source": [
    "boundaries = np.linspace(0, 150, 151) # 151 boundaries from 0 to 150 GeV.\n",
    "plt.hist (invariant_mass, bins=boundaries, label = \"CMS 2011 data\", histtype='step', linewidth=1)\n",
    "plt.hist (lowM, bins=boundaries, label = \"Low mass region\")\n",
    "plt.hist (midM, bins=boundaries, label = \"Mid mass region\")\n",
    "plt.hist (highM, bins=boundaries, label = \"High mass region\")\n",
    "plt.title (\"Invariant mass of the muon pairs\")\n",
    "plt.xlabel (\"Dimuon invariant mass [GeV/$c^2$]\")\n",
    "plt.ylabel (\"Number of dimuons\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-story",
   "metadata": {
    "id": "brown-story"
   },
   "source": [
    "Another common specification is `density = True` which allows to normalize the histogram. This is particularly useful when comparing the distributions of datasets composed by a different amount of samples. \n",
    "For example, let's consider the transverse momentum distribution at high and low mass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-mechanics",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "modern-mechanics",
    "outputId": "8cabe1bb-7a03-4783-d0aa-e9771bad357e"
   },
   "outputs": [],
   "source": [
    "boundaries = np.linspace (0, 60, 61)\n",
    "plt.hist ( df.query (\"M < 5\") ['pt1'], bins = boundaries, label=\"Low mass region\", density=True)\n",
    "plt.hist ( df.query (\"M > 70 and M < 110\") ['pt1'], bins = boundaries, label=\"High mass region\", histtype = 'step', density=True)\n",
    "\n",
    "\n",
    "plt.xlabel ('Transverse momentum of $\\mu_1$ [GeV/$c$]')\n",
    "plt.ylabel ('Normalized number of candidates')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-wonder",
   "metadata": {
    "id": "concerned-wonder"
   },
   "source": [
    "As expected, the decay of a heavier particle produces muons with higher transverse momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-manitoba",
   "metadata": {
    "id": "static-manitoba"
   },
   "source": [
    "## Filtering data from a panda DataFrame with `boolean` series\n",
    "The `query` function is extremely simple and useful for intuitive and exploratory analysis. Unfortunately only a tiny subset of the operations possible in Python are valid in the *pandas query language*. For this reason is sometimes useful to define a boolean series to filter the dataset. \n",
    "A boolean series is a `pandas series` associating to each index (corresponding to a row if the dataframe) a `True`/`False` value. When applied to a Series or to a DataFrame with the square-bracket operator, only the rows for which the boolean series is `True` are retained. \n",
    "\n",
    "Let's see an example. Let's start defining and inspecting a *boolean series* by selecting the rows with mass above 5 GeV/$c^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-developer",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "heated-developer",
    "outputId": "880c04ff-b5d5-4a09-d4ac-0c0da3df0c2c"
   },
   "outputs": [],
   "source": [
    "boolean_series = df['M'] > 5\n",
    "\n",
    "print (boolean_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-locator",
   "metadata": {
    "id": "limited-locator"
   },
   "source": [
    "We can then update the boolean series, requiring for example that the mass has to be also lower than 15 GeV/$c^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-blair",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "attractive-blair",
    "outputId": "95ecedfc-f307-46f6-d57c-bd42b83ac919"
   },
   "outputs": [],
   "source": [
    "boolean_series &= df['M'] < 15\n",
    "\n",
    "print (boolean_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-exhibit",
   "metadata": {
    "id": "roman-exhibit"
   },
   "source": [
    "Or equivalently,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-worry",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "upset-worry",
    "outputId": "5e420d04-77d0-4346-9889-8aaee51248fb"
   },
   "outputs": [],
   "source": [
    "same_boolean_series = (df['M'] > 5) & (df['M'] < 15)\n",
    "\n",
    "print (\"Are the two series equal, for all rows?\", np.all ( boolean_series == same_boolean_series ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-genre",
   "metadata": {
    "id": "present-genre"
   },
   "source": [
    " > **Note!** The AND operator used in the *query* languagge is `and` while in Python it is `&`. Indeed in Python, the `and` keyword is reserved for logic operation between boolean variables. An array or a series of boolean variables is not a boolean variable so that the `and` operator fails. The `&` operator, introduced in Python as bitwise operator, has been *pverridden* in the classes describing `numpy arrays` and `pandas series` to describe the and element-wise operator between elements of two same-sized objects. Similarly the `or` operator, valid in `query` language, is replaced by the `|` operator in Python.\n",
    " \n",
    " > **Note!** In Python the operator `&` has precedence over the comparison operators `>` and `<` as inherited from C. It is therefore important to protect the conditions within parentheses to avoid puzzling errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-equivalent",
   "metadata": {
    "id": "aerial-equivalent"
   },
   "source": [
    "Once the boolean series is defined, the square-bracket operator can be used to apply it to a given dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-liabilities",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spoken-liabilities",
    "outputId": "9e78d1af-0fb8-4392-fafd-176373fd2a88"
   },
   "outputs": [],
   "source": [
    "lowM = df [boolean_series]\n",
    "plt.hist ( lowM ['M'], bins = np.linspace(5,15,101) )\n",
    "plt.xlabel (\"Dimuon invariant mass [GeV/$c^2$]\")\n",
    "plt.ylabel (\"Number of dimuons\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-principle",
   "metadata": {
    "id": "inner-principle"
   },
   "source": [
    "## Adding columns to DataFrames with `eval`\n",
    "It is sometimes useful to add columns with partial results to the dataset, for example we may want to include the variables `theta1` and `theta2` describing the polar angles of the two muons.\n",
    "Similarly to what happens for the selection, as long as the operation is sufficiently simple we can use a `pandas` service function, named `eval` this time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-execution",
   "metadata": {
    "id": "sticky-execution"
   },
   "outputs": [],
   "source": [
    "extended_df = df.eval ( \"theta1 = arctan (pt1/pz1)\").eval (\"theta2 = arctan (pt2/pz2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-thumbnail",
   "metadata": {
    "id": "comfortable-thumbnail"
   },
   "source": [
    "Once the column is included in the dataset, we can deal with it exactly as with the original variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-firmware",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "timely-firmware",
    "outputId": "cdcaf1dc-4f79-4c3f-9587-92863e47bb4a"
   },
   "outputs": [],
   "source": [
    "thetaAxis = np.linspace ( -np.pi/2, np.pi/2, 101)\n",
    "plt.hist (extended_df['theta1'], bins = thetaAxis, label = \"Muon 1\")\n",
    "plt.hist (extended_df['theta2'], bins = thetaAxis, label = \"Muon 2\", histtype='step', linewidth=2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-luther",
   "metadata": {
    "id": "after-luther"
   },
   "source": [
    "## Adding Series to a DataFrame\n",
    "In case the `eval` function is not sufficient for the complexity of the operation we need to describe, we can define series with the new values and assign them to a given column in the DataFrame.\n",
    "\n",
    "As an example we compute the [pseudorapidity](https://en.wikipedia.org/wiki/Pseudorapidity) of the two muons, defined as \n",
    "$$\n",
    "\\eta = -\\log \\left[\\tan \\left(\\frac\\theta2\\right)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-frank",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "patient-frank",
    "outputId": "ed28b1ff-d094-44ce-c9ad-ad30c5d931ec"
   },
   "outputs": [],
   "source": [
    "eta1_series = -np.log ( np.tan (0.5 * np.abs(extended_df['theta1'])) ) \n",
    "eta2_series = -np.log ( np.tan (0.5 * np.abs(extended_df['theta2'])) ) \n",
    "print (\"Pseudorapidity of Muon2:\\n\", eta2_series)\n",
    "extended_df['eta1'] = eta1_series\n",
    "extended_df['eta2'] = eta2_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-combine",
   "metadata": {
    "id": "continent-combine"
   },
   "source": [
    "The two techniques can be easily mixed, for example we can define the average pseudorapidity of each muon pair as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-julian",
   "metadata": {
    "id": "final-julian"
   },
   "outputs": [],
   "source": [
    "extended_df['etaAvg'] = extended_df.eval(\"eta1 + eta2\")/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-sister",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "defined-sister",
    "outputId": "ca1daea8-7c92-4b36-c2ee-8e4f491c5fc2"
   },
   "outputs": [],
   "source": [
    "plt.hist (extended_df['eta1'], bins = np.linspace (0,3, 61), label = \"Muon 1\")\n",
    "plt.hist (extended_df['eta2'], bins = np.linspace (0,3, 61), label = \"Muon 2\", histtype='step', linewidth=2)\n",
    "plt.hist (extended_df['etaAvg'], bins = np.linspace (0,3, 61), label = \"Average\",\n",
    "          linestyle = '--', histtype='step', linewidth=2, color='red')\n",
    "plt.xlabel ( \"Muon pseudorapidity $\\eta$\")\n",
    "plt.ylabel ( \"Number of muons\" )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-frederick",
   "metadata": {
    "id": "appropriate-frederick"
   },
   "source": [
    "## Plotting trends and curves\n",
    "Let's consider the high mass region, where a well pronounced peak is visibile and contributions from non-resonant dimuons seems negligible.\n",
    "> **Curiosity**: This resonant contribution to the production of dimuons is due to decays of the $Z^0$ bosons to $\\mu^+\\mu^-$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-lodging",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "disabled-lodging",
    "outputId": "0a9b765d-f0ab-456b-ff19-1f0c30c2cb52"
   },
   "outputs": [],
   "source": [
    "boundaries = np.linspace (70, 110, 81)\n",
    "highM = extended_df.query ( \"M > 70 and M < 110\")\n",
    "plt.hist (highM['M'], bins=boundaries, label=\"CMS 2011 data\")\n",
    "plt.xlabel ( \"Dimuon mass [GeV/$c^2$]\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-eclipse",
   "metadata": {
    "id": "detailed-eclipse"
   },
   "source": [
    "We wonder if the average value of the peak is stable for event reconstructed in different regions of the detector, for example at different pseudorapidity.\n",
    "Let's consider the pseudorapidity distribution in this mass region,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-admission",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "intermediate-admission",
    "outputId": "6376701a-57fc-44c9-e42a-c1189a987ce1"
   },
   "outputs": [],
   "source": [
    "plt.hist (highM['etaAvg'], bins = np.linspace(0,2.5,51), label=\"High Mass region\")\n",
    "plt.xlabel (\"Muon pseudorapidity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-biography",
   "metadata": {
    "id": "august-biography"
   },
   "source": [
    "Let's divide the pseudorapidity in large bins, with approximately the same populations, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-pound",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "searching-pound",
    "outputId": "84997a07-288e-46a7-9091-a3460e0dd703"
   },
   "outputs": [],
   "source": [
    "eta_boundaries = 0, 0.85, 1.05, 1.2, 1.35, 1.5, 1.65, 1.85, 2.5\n",
    "\n",
    "plt.hist (highM['etaAvg'], bins = np.linspace(0,2.5,51), label=\"High Mass region\")\n",
    "## Gets the boundaries of the y axis to draw the separators\n",
    "ylow, yhigh = plt.gca().get_ylim()\n",
    "for boundary in eta_boundaries:\n",
    "    plt.plot ( (boundary, boundary), (ylow, yhigh), linestyle='--', color='red', alpha = 0.5 )\n",
    "    \n",
    "plt.xlabel (\"Muon pseudorapidity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-maple",
   "metadata": {
    "id": "dried-maple"
   },
   "source": [
    "First of all, we check whether we succeeded in our attempt of getting similar population.\n",
    "Note how we construct the loop over the bins starting from the sequence of boundaries. \n",
    "We consider two copies of the original sequence, one containing all but the last entry will represent the lower limit of each bin, the other one, containing all but the first entry, will represent the higher boundary of each bin. \n",
    "Through the `zip` iterator we make loop on the pairs of boundaries.\n",
    "\n",
    "Once we have the boundaries for each bin, we can use the Python `len` instruction to count the number of rows selected with a `query` instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-latitude",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cosmetic-latitude",
    "outputId": "565e80de-bb22-4645-efca-163995274604"
   },
   "outputs": [],
   "source": [
    "for low, high in zip(eta_boundaries[:-1], eta_boundaries[1:]):\n",
    "    n_entries = len(highM.query(f\"etaAvg >= {low} and etaAvg < {high}\"))\n",
    "    print (f\"Eta bin from {low:.2f} to {high:.2f} contains {n_entries} candidates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-referral",
   "metadata": {
    "id": "middle-referral"
   },
   "source": [
    "Following the same scheme, we can now compute different quantities, such as the average value of the dimuon invariant mass (`np.mean`) or its root mean squared error (`np.std`).\n",
    "\n",
    "For each bin, we append to a list the central value of the bin and the results of our computations. One list per result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-trainer",
   "metadata": {
    "id": "ahead-trainer"
   },
   "outputs": [],
   "source": [
    "bin_centers = []\n",
    "bin_averages = []\n",
    "bin_rmss = []\n",
    "for low, high in zip(eta_boundaries[:-1], eta_boundaries[1:]):\n",
    "    bin_centers.append (0.5*(low+high))\n",
    "    bin_df = highM.query(f\"etaAvg >= {low} and etaAvg < {high}\")\n",
    "    bin_averages.append ( np.mean (bin_df['M']) )\n",
    "    bin_rmss.append ( np.std (bin_df['M']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-botswana",
   "metadata": {
    "id": "premium-botswana"
   },
   "source": [
    "Once the list are filled, we can use the `plot` function of `pyplot` to render the variation of the results across the different bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-explorer",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ideal-explorer",
    "outputId": "4542c578-c9b1-4fb5-8405-ec1ac3fb3e4c"
   },
   "outputs": [],
   "source": [
    "plt.plot (bin_centers, bin_averages, 'o-')\n",
    "plt.xlabel(\"Muon pseudorapidity (average)\")\n",
    "plt.ylabel(\"Mean of the $Z^0$ mass peak [GeV/$c^2$]\")\n",
    "plt.show()\n",
    "plt.plot (bin_centers, bin_rmss, 'o-')\n",
    "plt.xlabel(\"Muon pseudorapidity (average)\")\n",
    "plt.ylabel(\"RMS of the $Z^0$ mass peak [GeV/$c^2$]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-guarantee",
   "metadata": {
    "id": "bright-guarantee"
   },
   "source": [
    "### Bonus track\n",
    "In the following cell we show an example of profile plot, where we show for each pseudorapidity bin the mean and the 1$\\sigma$ band of the transverse momentum distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-hobby",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "superb-hobby",
    "outputId": "8369f5ef-6615-4040-abdd-68a6e29d886a"
   },
   "outputs": [],
   "source": [
    "bin_centers = []\n",
    "pt_low = []\n",
    "pt_high = []\n",
    "pt_average = []\n",
    "for low, high in zip(eta_boundaries[:-1], eta_boundaries[1:]):\n",
    "    bin_df = highM.query(f\"etaAvg >= {low} and etaAvg < {high} and pt1 < 1000 and pt2 < 1000 \")\n",
    "    bin_centers.append (np.quantile(bin_df['etaAvg'], 0.5))\n",
    "    pts = np.concatenate ((bin_df['pt1'], bin_df['pt2']))\n",
    "    pt_average.append (np.mean(pts))\n",
    "    pt_low.append (np.quantile(pts, 0.5-0.68/2))\n",
    "    pt_high.append (np.quantile(pts, 0.5+0.68/2))\n",
    "\n",
    "lower_boundaries = np.array(eta_boundaries[:-1])\n",
    "upper_boundaries = np.array(eta_boundaries[1:])\n",
    "bin_centers = np.array(bin_centers)\n",
    "pt_low = np.array(pt_low)\n",
    "pt_high = np.array(pt_high)\n",
    "pt_average = np.array (pt_average)\n",
    "plt.errorbar (x=bin_centers, y=pt_average, xerr=(bin_centers-lower_boundaries, upper_boundaries-bin_centers), yerr=(pt_average-pt_low, pt_high-pt_average), fmt='ko')\n",
    "plt.xlabel (\"Muon Pseudorapidity\")\n",
    "plt.ylabel (\"Muon transverse momentum [GeV/$c$]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-peripheral",
   "metadata": {
    "id": "hollow-peripheral"
   },
   "source": [
    "# Reading nTuples with `uproot`\n",
    "Most of the dataset in *particle physics* are made available in a binary format defined within the [ROOT framework](https://root.cern). \n",
    "In ROOT, datasets are usually organized in [`TTree`s](https://root.cern.ch/doc/master/classTTree.html) objects stored in a [TFile](https://root.cern.ch/doc/master/classTFile.html). A unique `key` identifies each `TTree` in a `TFile`.\n",
    "A `TTree` is composed of `TBranch`es which are a generalization of columns. Each `TBranch` can have several leaves that actually contain the data. \n",
    "Often for data analysis `TTree`s are used to represent data in a tabular format, where the `TTree` is simply a table and the `TBranch`es are simply its columns. This data format is usually referred to as *nTuple*s. \n",
    "\n",
    "ROOT files, and in particular *nTuples* can be accessed without installing the full ROOT framework using [uproot](https://github.com/scikit-hep/uproot3). \n",
    "\n",
    "If missing on your system, `uproot` can be installed simply with \n",
    "```\n",
    "pip install --upgrade uproot\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-excess",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rough-excess",
    "outputId": "ef31fbde-dcc7-4ec2-bf2e-2a867effdebe"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade uproot\n",
    "import uproot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-advance",
   "metadata": {
    "id": "christian-advance"
   },
   "source": [
    "`uproot` is designed to access dataset stored in one or more `.root` files as `TTree` and translate them into `DataFrame` or other formats to ease data analysis.\n",
    "Let's consider for example the LHCb dataset of $D^0 \\to K^- \\pi^+$ decays used for the LHC Masterclass programme: https://opendata.cern.ch/record/401\n",
    "This dataset contains about $90 \\times 10^3$ decay candidates for the $D^0$ or $\\bar D^0$ mesons to a kaon and a pion. \n",
    "\n",
    "The $D^0$ meson is composed of a charm quark and an anti-up anti-quark ($c\\bar u$), while the $\\bar D^0$ meson, its anti-particle, is composed of an anti-charm anti-quark and an up quark ($\\bar cu$). \n",
    "\n",
    "To read the dataset into a `DataFrame`, let's first define the list of files to open and the list of branches we are interested in:\n",
    " * `D0_PT` which represents the transverse momentum of the $D^0$ hadron;\n",
    " * `D0_MM` which represents the invariant mass of the $K^\\pm\\pi^\\mp$ combination;\n",
    " * `D0_TAU` which represents the proper decay time of the $D^0$ meson;\n",
    " * `D0_MINIPCHI2` which is a measure of the inconsistency of the $D^0$ trajectory with the proton-proton collision (or primary vertex). A large $\\chi^2$ indicates poor consistency and points towards a secondary production of the $D^0$ meson (for example from a $b$-hadron decay) or random combinations of kaon and pions produced in different proton-proton interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1caf633-56ff-455d-af07-c34c4de28e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "uproot.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-binding",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "supposed-binding",
    "outputId": "43b2b351-89d1-4192-fb1f-26a44f717596"
   },
   "outputs": [],
   "source": [
    "\n",
    "file = \"https://opendata.cern.ch/record/401/files/MasterclassData.root\"\n",
    "branches = [\"D0_MINIPCHI2\", \"D0_PT\", \"D0_MM\", \"D0_TAU\"]\n",
    "df = uproot.open(file)['DecayTree'].arrays(branches, library='pd')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-difficulty",
   "metadata": {
    "id": "national-difficulty"
   },
   "source": [
    "As discussed above, we can now plot the distributions of these variables and analyse the dataset.\n",
    "This dataset is used in the LHCb masterclass to drive high-school students into the measurement of the $D^0$ lifetime by fitting the decay time distribution, properly treating the background contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-simon",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "indie-simon",
    "outputId": "86ebf534-23e7-47ff-8662-288550d34710",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8), dpi=100)\n",
    "plt.subplot(221)\n",
    "plt.hist ( df['D0_MM'], bins = np.linspace(1815, 1915, 101))\n",
    "plt.xlabel ( \"$m (K^-\\pi^+)$ [MeV/$c^2$]\")\n",
    "plt.ylabel ( \"$D^0 \\\\to K^- \\pi^+$ candidates\")\n",
    "plt.subplot(222)\n",
    "plt.hist ( df['D0_PT']*1e-3, bins = np.linspace(2, 10, 161))\n",
    "plt.yscale ('log')\n",
    "plt.xlabel ( \"$D^0$ transverse momentum [GeV/$c$]\")\n",
    "plt.ylabel ( \"$D^0 \\\\to K^- \\pi^+$ candidates\")\n",
    "plt.subplot(223)\n",
    "plt.hist ( df['D0_TAU']*1e3, bins = np.linspace(0, 4, 161))\n",
    "plt.xlabel ( \"$D^0$ proper decay time [ps]\")\n",
    "plt.ylabel ( \"$D^0 \\\\to K^- \\pi^+$ candidates\")\n",
    "plt.yscale ('log')\n",
    "plt.subplot(224)\n",
    "plt.hist ( np.log(df['D0_MINIPCHI2']), bins = np.linspace(-5, 15, 101))\n",
    "plt.xlabel ( \"$\\log\\,\\chi^2_{\\mathrm{IP}}$\")\n",
    "plt.ylabel ( \"$D^0 \\\\to K^- \\pi^+$ candidates\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-picture",
   "metadata": {
    "id": "stretch-picture"
   },
   "source": [
    "# Supplementary material\n",
    "\n",
    "### First step\n",
    "Split the dataset in two subsamples one containing only background events, for example invariant masses in the two range s  (1820, 1840) and (1890, 1910) MeV/$c^2$, named **background** and one region, named **signal box** containing signal and background with invariant mass in the range (1850, 1880) MeV/$c^2$.\n",
    "\n",
    "The number of events in the signal box is due to the sum of $S$ signal event and $B$ background events. \n",
    "If the number of events in the **signal box** is $s$ and the number of events **background** region is $b$, then\n",
    "$$\n",
    "s = S+B \\\\[5mm]\n",
    "B \\approx \\frac{(1880 - 1850)\\ \\mathrm{MeV}/c^2}{(1840 - 1820) + (1910 - 1890)\\ \\mathrm{MeV}/c^2} \\ b\n",
    "$$\n",
    "\n",
    "which results in the following expression for the number of signal events\n",
    "\n",
    "$$\n",
    "S \\approx s - \\frac{(1880 - 1850)\\ \\mathrm{MeV}/c^2}{(1840 - 1820) + (1910 - 1890)\\ \\mathrm{MeV}/c^2} \\ b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-wednesday",
   "metadata": {
    "id": "psychological-wednesday"
   },
   "source": [
    "### Second step\n",
    "Study the number of signal and background events in bins of the $D^0$ transverse momentum. \n",
    "\n",
    "The number of signal events should decrease more slowly increasing $p_T$ than the background yield. This indicates that removing the low transverse momentum events should increase the purity of the selected sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-logan",
   "metadata": {
    "id": "negative-logan"
   },
   "source": [
    "### Third step\n",
    "Define and plot the signal purity and the background rejection as a function of a threshold on the transverse momentum of the $D^0$ hadron. \n",
    "\n",
    "Signal purity is defined as \n",
    "$$\n",
    "\\mathrm{purity}(p_{\\mathrm{T}, min}) = \\frac{S (p_\\mathrm{T} > p_{\\mathrm{T}, min})}{S (p_\\mathrm{T} > p_{\\mathrm{T}, min}) + B (p_\\mathrm{T} > p_{\\mathrm{T}, min})}\n",
    "$$\n",
    "\n",
    "Background-rejection is defined as \n",
    "$$\n",
    "\\mathrm{rejection}(p_{\\mathrm{T}, min}) = \\frac{B - B (p_\\mathrm{T} > p_{\\mathrm{T}, min})}{B}\n",
    "$$\n",
    "\n",
    "where $S(cut)$ indicates the number of signal events once *cut* is applied, and similarly $B(cut)$ indicates the number of background events once *cut* is applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-bonus",
   "metadata": {
    "id": "isolated-bonus"
   },
   "source": [
    "### Fourth step\n",
    "Define a function that takes as an input the dataframe and three thresholds on $p_T$, $\\log\\chi^2_{\\mathrm{IP}}$ and $D^0$ decay time and return the detection significance defined as \n",
    "\n",
    "$$\n",
    "cut = \\left(p_\\mathrm{T} > p_\\mathrm{{T}, min}\\qquad \\& \\qquad \\log\\chi^2_{\\mathrm{IP}} < \\log\\chi^2_{\\mathrm{IP, \\mathrm{max}}} \\qquad \\& \\qquad \\tau_D > \\tau_{D,min}\\right)\\\\[5mm] \n",
    "\\mathrm{significance} = \\frac{S (cut)}{\\sqrt{S(cut) + B (cut)+1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-ideal",
   "metadata": {
    "id": "dressed-ideal"
   },
   "source": [
    "### Fifth step (bonus, not discussed in next lectures)\n",
    "Try using `scipy.optimize` module to maximise the significance."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
