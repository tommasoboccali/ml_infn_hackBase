{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Y8mytY6WVcF"
   },
   "source": [
    "#Tutorial on CNN\n",
    "We try to build a DNN that recognize if an image contains a rectangle or a circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxgS64DmqCrH"
   },
   "source": [
    "## Import useful stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jO_-Tguu60O9"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from math import *\n",
    "from matplotlib import pyplot as plt \n",
    "import tensorflow as tf\n",
    "#device_name = tf.test.gpu_device_name()\n",
    "#print(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcejQQHu8WQa"
   },
   "source": [
    "## Lets generate some data\n",
    "\n",
    "We now generate ourself some images with a circle or a rectangle, of random color, in a random position.\n",
    "\n",
    "Three different modes of generating the images are implemented:\n",
    "\n",
    "*   A single shape per figure\n",
    "*   Multiple shapes mixed in each figure\n",
    "*   A single figure keeping track of the \"bounding box\"\n",
    "\n",
    "\n",
    "\n",
    "### Additional Exercise\n",
    "1. Try adding some random noise in the image background\n",
    "2. Try adding more classes such e.g. Lines or Ellipses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGItu2U4lVh7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "addnoise=False\n",
    "simple =True #single shape per figure\n",
    "mixed  =False #multi shapes per figure\n",
    "withBB =False  #one shape with bounding boxes\n",
    "\n",
    "\n",
    "def background():\n",
    "  #here one can add noise\n",
    "  if addnoise:\n",
    "    return np.array(np.random.rand(64,64,3)*20+100,np.uint8)\n",
    "  else :\n",
    "    return np.zeros((64,64,3), np.uint8)\n",
    "\n",
    "def randomColor():\n",
    "  return (int(np.random.rand()*128+128),int(np.random.rand()*128+128),int(np.random.rand()*128+128))\n",
    "\n",
    "def drawCircle(c,x,y,r):\n",
    "  img = background()\n",
    "  cv2.circle(img,(x,y),r,c, -1)\n",
    "  return img,x-r,y-r,x+r,y+r#return image and bounding box\n",
    "\n",
    "def genCircle():\n",
    "  return drawCircle(randomColor(),int(np.random.rand()*50)+10,int(np.random.rand()*50)+10,\n",
    "                    int(np.random.rand()*6)+3)\n",
    "\n",
    "def drawRectangle(c,x,y,w,h):\n",
    "  img = background()\n",
    "  cv2.rectangle(img,(x,y),((x+w),(y+h)), c, -1)\n",
    "  return img,x,y,x+w,y+h #return image and bounding box\n",
    "\n",
    "def genRectangle():\n",
    "  return drawRectangle(randomColor(),int(np.random.rand()*40)+10,int(np.random.rand()*40)+10,\n",
    "                       int(np.random.rand()*12)+5,int(np.random.rand()*12)+5)\n",
    "\n",
    "def genN(f,i):\n",
    "  img = np.zeros((64,64,3), np.uint8)\n",
    "  for x in range(i):\n",
    "    img+=f()[0] #discard bb info, take only image\n",
    "  return img\n",
    "\n",
    "nsamples=1000\n",
    "\n",
    "#produce figures with either a rectangle or a circle\n",
    "if simple :\n",
    "  targets=np.random.rand(nsamples) > 0.5  \n",
    "  images=np.array([genCircle()[0] if targets[x] else genRectangle()[0] for x in range(nsamples)])\n",
    "\n",
    "\n",
    "if mixed:\n",
    "#produce figure with n rectangles and m circles\n",
    "  targets=np.array([(int(np.random.rand()*4),int(np.random.rand()*4)) for x in range(nsamples) ])\n",
    "  images=np.array([genN(genRectangle,targets[x,0])+genN(genCircle,targets[x,1]) for x in range(nsamples)])\n",
    "\n",
    "if withBB : \n",
    "#produce figures with either a rectangle or a circle\n",
    "  targets=np.array([np.random.rand()>0.5 for x in range(nsamples) ])\n",
    "  imagesWithBB=[genCircle() if targets[x] else genRectangle() for x in range(nsamples)]\n",
    "  images=np.array([imagesWithBB[x][0] for x in range(nsamples)])\n",
    "  boundingBoxes=np.array([imagesWithBB[x][1:] for x in range(nsamples)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XArMXTtMW97o"
   },
   "source": [
    "Let's show a few of the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "YiUPPdZ6pNsi",
    "outputId": "484dd2ef-1315-44bc-d28f-ba452d624882"
   },
   "outputs": [],
   "source": [
    "print(targets.shape)\n",
    "print(images.shape)\n",
    "#print(targets)\n",
    "print(targets[:2])\n",
    "plt.imshow(images[0])\n",
    "plt.show()\n",
    "plt.imshow(images[1])\n",
    "\n",
    "if withBB:\n",
    "  print(boundingBoxes.shape)\n",
    "  print(boundingBoxes[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeU8chiYxtSu"
   },
   "source": [
    "We concatenate zeroes and ones as labels and the shuffle with the same permutation both the data and the labels.\n",
    "## Exercise\n",
    "3. If we have more categories (let say N) we should use a categorical label that is a vector of length N with 1 on the category(/ies) the image belong to and 0 in the others. Try to build a categorical label for two categories (e.g. using numpy \"tile\" function to repeat the same raw multiple times )\n",
    "4. Expand the categorical label to  Ellispes or  Lines  and possibly also non exclusive categories such has 2D vs 1D objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MN1px9PfBp9y"
   },
   "outputs": [],
   "source": [
    "if withBB :\n",
    "    labels=[targets,boundingBoxes] \n",
    "else:\n",
    "    labels=targets\n",
    "\n",
    "data=images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NibVPZhC3hL"
   },
   "source": [
    "# Let's build a CNN \n",
    "\n",
    "Now we build our first CNN. We have some Conv layers interleaved with MaxPooling\n",
    "\n",
    "Finally we flatten the output of the convolutional stack and appply a Dense FF\n",
    "\n",
    "### MaxPooling\n",
    "![alt text](https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png)\n",
    "\n",
    "### Exercise\n",
    "5. Try adding/removing convolutional layers, change the kernel size, try to add dropout\n",
    "6. Try changing the model to categorical labels, change loss function from binary_crossentropy to categorical_crossentropy, and use softmax activation instead of sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pJLV4GOu9vGu",
    "outputId": "c89d1034-3236-43db-c90b-b67029575e40"
   },
   "outputs": [],
   "source": [
    "inputs=Input(shape=(64,64,3,))\n",
    "hidden=  Conv2D(5,(5,5), activation='relu')(inputs)\n",
    "hidden= MaxPooling2D((3,3))(hidden)\n",
    "hidden=  Conv2D(3,(3,3), activation='relu')(hidden)\n",
    "hidden= MaxPooling2D((3,3))(hidden)\n",
    "#hidden=  Conv2D(3,(3,3), activation='relu')(hidden)\n",
    "hidden= Flatten()(hidden)\n",
    "#hidden=  Dense(50, activation='relu')(hidden)\n",
    "#hidden=  Dense(40, activation='relu')(hidden)\n",
    "hidden=  Dense(30, activation='relu')(hidden)\n",
    "if simple : \n",
    "  outputs = Dense(1, activation='sigmoid')(hidden)\n",
    "  loss=\"binary_crossentropy\"\n",
    "if mixed : \n",
    "  outputs = Dense(2, activation='relu')(hidden)\n",
    "  loss='MSE'\n",
    "if withBB : \n",
    "  output1 = Dense(1, activation='sigmoid')(hidden)\n",
    "  output2 = Dense(4, activation='linear')(hidden)\n",
    "  outputs=[output1,output2]\n",
    "  loss=[\"binary_crossentropy\",\"MSE\"]\n",
    "  \n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss=loss, optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6JmJFU-9vtN"
   },
   "source": [
    "And now let's fit it to our data.\n",
    "The sample is automatically split in two so that 50% of it is used for validation and the other half for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRMhsQ2nC6oa",
    "outputId": "76adedbc-da18-4f7b-db61-ee4ec40d2162"
   },
   "outputs": [],
   "source": [
    "history=model.fit(data,labels,validation_split=0.5,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKGPKoUU0Ou0"
   },
   "source": [
    "*history* contains information about the training.  We can now now show the loss vs epoch for both validation and training samples.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lu2OdNE5OeXb",
    "outputId": "a982ad96-f923-4d1a-93fe-abaffe182eba"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "#plt.plot(history.history[\"val_accuracy\"])\n",
    "#plt.plot(history.history[\"accuracy\"])\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKxqLjPvEqX3",
    "outputId": "be63e58a-2fee-47b8-87ae-34351afc9da3"
   },
   "outputs": [],
   "source": [
    "print(model.predict(np.expand_dims(genRectangle()[0],axis=0) ))\n",
    "print(model.predict(np.expand_dims(genCircle()[0],axis=0) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWGckuGjZRjm"
   },
   "source": [
    "Let's try to mix an image with circles and rectangles and see how the network would evaluate it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ej1RCfrcZPLp"
   },
   "outputs": [],
   "source": [
    "if mixed :\n",
    "  im= genCircle()[0]+genRectangle()[0]+genRectangle()[0]\n",
    "  #print(\"Looks like a\", (\"circle\" if model.predict(np.expand_dims(im,axis=0) )[0,1] > 0.5 else \"rectangle\"))\n",
    "  print(\"There are \", model.predict(np.expand_dims(im,axis=0) )[0])\n",
    "  plt.imshow(im)\n",
    "  plt.show()\n",
    "\n",
    "if withBB:\n",
    "  im,x1,y1,x2,y2= genCircle()\n",
    "  pre=model.predict(np.expand_dims(im,axis=0) )\n",
    "  isCircle=pre[0][0]\n",
    "  x1p=pre[1][0][0]-1.\n",
    "  y1p=pre[1][0][1]-1.\n",
    "  x2p=pre[1][0][2]+1.\n",
    "  y2p=pre[1][0][3]+1.\n",
    "  print(x1p,y1p,x2p,y2p)\n",
    "  #print(\"Looks like a\", (\"circle\" if model.predict(np.expand_dims(im,axis=0) )[0,1] > 0.5 else \"rectangle\"))\n",
    "  print(\"It is a\",\"circle\" if isCircle > 0.5 else \"rectangle\" )\n",
    "  cv2.rectangle(im,(x1-1,y1-1),(x2+1,y2+1), (255,0,0), 1)\n",
    "  cv2.rectangle(im,(int(x1p),int(y1p)),(int(x2p),int(y2p)), (255,255,0), 1)\n",
    "  plt.imshow(im)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Se-3QB9YZuXX"
   },
   "source": [
    "The following code can be used to visualize what features the first conv layer is looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "vSgEZ2S4qyKi",
    "outputId": "aac5c94f-d314-4f89-e919-ba6f0502e9a5"
   },
   "outputs": [],
   "source": [
    "# retrieve weights from the second hidden layer\n",
    "filters, biases = model.layers[1].get_weights()\n",
    "# normalize filter values to 0-1 so we can visualize them\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)\n",
    "# plot first few filters\n",
    "n_filters, ix =3, 1\n",
    "for i in range(n_filters):\n",
    "\t# get the filter\n",
    "\tf = filters[:, :, :, i]\n",
    "\t# plot each channel separately\n",
    "\tfor j in range(3):\n",
    "\t\t# specify subplot and turn of axis\n",
    "\t\tax = plt.subplot(n_filters, 4, ix)\n",
    "\t\tax.set_xticks([])\n",
    "\t\tax.set_yticks([])\n",
    "\t\t# plot filter channel in grayscale\n",
    "\t\tplt.imshow(f[:, :, j], cmap=['Reds','Greens','Blues'][j])\n",
    "\t\tix += 1\n",
    "\tax = plt.subplot(n_filters, 4, ix)\n",
    "\tax.set_xticks([])\n",
    "\tax.set_yticks([])\n",
    "\tplt.imshow(f)\n",
    "\tix += 1\n",
    "\n",
    "\n",
    "# show the figure\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
