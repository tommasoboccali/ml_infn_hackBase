{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6D7zwPJGMIq"
   },
   "source": [
    "#### ML_INFN Hackathon - Entry level\n",
    "# The basics of the Classification task, a classical application to High Energy Physics\n",
    "**Contact**: Lucio.Anderlini [at] fi.infn.it\n",
    "\n",
    "\n",
    "In the previous lectures we introduced the concept of Deep Neural Network and we introduced the tasks of regression and classification.\n",
    "We have also introduced Jupyter, numpy, pandas and keras as a framework for numerical data analysis.\n",
    "\n",
    "In this notebook we will see a first application of a very simple neural network to perform classification.\n",
    "We will frame our problem in the context of High Energy Physics, but the concepts and the methods we discuss are more general.\n",
    "\n",
    "#### Problem statement\n",
    "Given a dataset of simulated collisions as obtained assuming the Standard Model and theoretical contributions beyond the Standard Model, we aim at enhancing our ability of idenifying such contributions in acquired data by combining the discrimination power of multiple variables.\n",
    "\n",
    "**Disclaimer.** The purpose of this exercise is to provide a wide overview of the logical procedure for applying multivariate classifiers in High Energy Physics. It is not meant to provide a complete guide for applying machine learning to real-world analyses.\n",
    "\n",
    "#### Dataset\n",
    "We will discuss the classification problem on a reduced version of the [HEPMASS dataset](http://archive.ics.uci.edu/dataset/347/hepmass), made [available](https://pandora.infn.it/public/cba2c5/dl/reduced_hepmass_fixed.feather) on INFN pandora.\n",
    "\n",
    "The dataset is stored in *feather* format and features the following columns:\n",
    " * `label`: 0 for the Standard Model events, 1 for the BSM contributions;\n",
    " * `mass`: the mass of a hypothetical new particle beyond the Standard Model, or NaN for a Standard Model event\n",
    " * `pt1` and `pt2`: proxies for low-level quantities (in this case representing the transverse momentum of reconstructed particles)\n",
    " * `m1` and `m2`: proxies for high-level quantities (in this case representing invariant masses of particle pairs)\n",
    "\n",
    "\n",
    "In this exercise, we will restrain the problem to a single mass hypothesis,while exploring the techniques to handle the theoretical uncertainty on the mass of the hypothetical particle is left to the reader.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foZOWdPWJvBj"
   },
   "source": [
    "## Getting started\n",
    "\n",
    " * Importing the libraries\n",
    " * Downloading the dataset\n",
    " * Selecting the dataset relevant to the exercise (defining the mass hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "970jsPi_c0kB",
    "outputId": "2668902b-94b6-4a53-d9a1-e3981c8b4baa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "!pip install -q pyarrow\n",
    "\n",
    "df = (pd\n",
    "      .read_feather(\"https://pandora.infn.it/public/cba2c5/dl/reduced_hepmass_fixed.feather\")\n",
    "      .query(\"label == 0 or mass == 1000\")\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKkvyBeMKFAD"
   },
   "source": [
    "### Splitting the dataset into **Signal** and **Background**\n",
    "\n",
    "We are trying to enhance the new physics contributions making them stand over the known, Standard Model part.\n",
    "Hence, we will call *Background* the Standard Model contribution that we are trying to reject and *Signal* the contributions we are trying to enhance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQXzFwdxc39A",
    "outputId": "d3486d48-202f-4bdc-f903-47e4e4c50438"
   },
   "outputs": [],
   "source": [
    "sig = df.query(\"label == 1\")\n",
    "bkg = df.query(f\"label == 0\")\n",
    "\n",
    "print (f\"Selected {len(sig)} signal events and {len(bkg)} background events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zE1VZr4FLL-8"
   },
   "source": [
    "## Explorative analysis and feature selection\n",
    "\n",
    "We begin plotting the distributions with respect to the four variables for the signal and background, separately.\n",
    "\n",
    "This exploratory step is often useful to discard features providing no discrimination power between signal and background.\n",
    "\n",
    "Sometimes, it is also used to identify the \"most\" discriminant variable which is used in the last part of the analysis to \"visualize\" the signal and background contributions, possibly performing a counting experiment.\n",
    "We will use the feature `m2` to the purpose.\n",
    "\n",
    "In this dataset, the features are already preprocessed, scaling them to be roughly centered in zero and with a standard deviation of the order of 1.\n",
    "\n",
    "In general, preprocessing should be applied at this stage in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "ShXwpX3Xdb7d",
    "outputId": "a6397201-6be9-41af-980e-ce60ea6174e4"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "all_vars = ['pt1', 'pt2', 'm1', 'm2']\n",
    "for iPlot, var in enumerate(all_vars, 1):\n",
    "    plt.subplot(2, 2, iPlot)\n",
    "    _, bins = np.histogram(df[var], bins=100)\n",
    "    plt.hist(sig[var], bins, label=\"Signal\", histtype='step', linewidth=2, density=True)\n",
    "    plt.hist(bkg[var], bins, label=\"Background\", histtype='step', linewidth=2, density=True)\n",
    "    plt.xlabel(var)\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpoclrgnMfXJ"
   },
   "source": [
    "# A very simple classifier\n",
    "\n",
    "Let's define a minimal classifier.\n",
    "\n",
    "To speed-up the training, we pick only a subset of the dataset, for example the first 10'000 events.\n",
    "\n",
    "We define the model, the loss function, the optimizer and then we perform the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRgxudq_eXW1",
    "outputId": "02065c05-4a65-4a00-a99a-94f04c4d6a63"
   },
   "outputs": [],
   "source": [
    "dfh = df.head(10_000)\n",
    "\n",
    "vars = ['pt1', 'pt2', 'm1']\n",
    "\n",
    "classifier = tf.keras.models.Sequential()\n",
    "classifier.add (tf.keras.layers.Dense(128, activation='tanh'))\n",
    "classifier.add (tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "classifier.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "history = classifier.fit(dfh[vars].values, dfh['label'], batch_size=1024, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5qEiPHMOmPh"
   },
   "source": [
    "Keras returns the history of the training from the `fit` function, but one should be very careful interpretating the loss of the training set.\n",
    "Indeed, overtraining and undertraining effects would be very difficult to spot and identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "aiz5HTfZfuqt",
    "outputId": "e9aa802f-3e96-44da-88e7-017802c24f1c"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Binary Crossentropy\")\n",
    "plt.title(\"Simple classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq2tTOw3O9Kq"
   },
   "source": [
    "## The distribution of the DNN response\n",
    "\n",
    "The output of the Neural Network is sometimes called generically the \"Response\" of the classification. This names is used to stress that the statistical interpretation of this number is more complicated than a probability, even if it is defined between 0 and 1.\n",
    "\n",
    "For the ideal classifier, with complete knowledge on the generative joint PDFs of the input features, this would indeed be the probability of picking a signal event, from the training dataset, given the input features.\n",
    "Unfortunately, often the ratio of signal and background entries in the final dataset is not the same as in the training dataset.\n",
    "\n",
    "In other words, if there is no new physics in the acquired data, the probability of picking a new-physics event is exactly zero independently of what your Neural Network responds.\n",
    "\n",
    "The distribution of the response is however interesting because it allows to spot immediately pathological behaviours in the learning procedure. Usually you expect a distribution with the background peaking towards 0 and the signal peaking towards 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "JqZllT46gSFF",
    "outputId": "ed044c8f-07c8-4dd7-bdd6-9f9f95ac9ce6"
   },
   "outputs": [],
   "source": [
    "y_hat = classifier.predict(dfh[vars].values)\n",
    "\n",
    "plt.hist(y_hat[dfh.label==1], bins = np.linspace(0, 1, 101), label=\"Signal\", histtype='step', linewidth=2, density=True)\n",
    "plt.hist(y_hat[dfh.label==0], bins = np.linspace(0, 1, 101), label=\"Background\", histtype='step', linewidth=2, density=True)\n",
    "plt.xlabel(\"DNN Response\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrSssDGhQzfp"
   },
   "source": [
    "## Defining a validation sample\n",
    "\n",
    "Let's extend our example to use a validation sample.\n",
    "We can randomly pick some thousands of events from our training dataset and assign them to the validation.\n",
    "\n",
    "Validation datasets should not be used for training, as their purpose is to evaluate the ability of the trained algorithm to generalze to a dataset never used in the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIjSBuBwgnDF",
    "outputId": "d665142b-6caf-4c40-cb15-2616a5898280"
   },
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.Sequential()\n",
    "classifier.add (tf.keras.layers.Dense(128, activation='tanh'))\n",
    "classifier.add (tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "classifier.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "dfh = df.head(10_000)\n",
    "\n",
    "## Here we randomly select 2048 entries from the dataset\n",
    "df_validation = dfh.sample(2048)\n",
    "\n",
    "## And we drop them from the training dataset\n",
    "df_train = dfh[~dfh.index.isin(df_validation.index)]\n",
    "\n",
    "history = classifier.fit(\n",
    "    df_train[vars].values,\n",
    "    df_train['label'],\n",
    "\n",
    "    ## Here we define the validation data to monitor the generalization abilities of the NN,\n",
    "    ## already during the training\n",
    "    validation_data=(df_validation[vars], df_validation['label']),\n",
    "    batch_size=1024,\n",
    "    epochs=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1wLiT6dSiwM"
   },
   "source": [
    "## The evolution of the loss function\n",
    "\n",
    "Now the evolution of the loss function is more interesting as it make it possible to identify deviations between the loss evaluated on the training and validation samples, raising concerns about possible overtraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "9ka8MPHJin_o",
    "outputId": "205137d6-5f91-46e8-c69d-f7058044fefc"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Binary Crossentropy\")\n",
    "plt.title(\"Simple classifier\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQxIxYXCS8fD"
   },
   "source": [
    "A further test on the ability of the neural network to generalize is to compare the distribution of the DNN response as obtained from the training and the validation samples.\n",
    "\n",
    "If the DNN is capable of generalizing, then we expect the two distributions to overlap. Otherwise they will display discrepancies, with the signal and background components in the validation dataset being less \"separated\" than in the \"training\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "FjPXM8fgh4ru",
    "outputId": "64058327-45eb-4385-9409-552c2216b7b6"
   },
   "outputs": [],
   "source": [
    "y_train_hat = classifier.predict(df_train[vars].values)\n",
    "y_validation_hat = classifier.predict(df_validation[vars].values)\n",
    "\n",
    "plt.hist(y_train_hat[df_train.label==1], bins = np.linspace(0, 1, 101), label=\"Signal\", histtype='step', linewidth=2, density=True)\n",
    "plt.hist(y_train_hat[df_train.label==0], bins = np.linspace(0, 1, 101), label=\"Background\", histtype='step', linewidth=2, density=True)\n",
    "plt.hist(y_validation_hat[df_validation.label==1], bins = np.linspace(0, 1, 101), label=\"Signal (validation)\", histtype='step', linewidth=2, density=True)\n",
    "plt.hist(y_validation_hat[df_validation.label==0], bins = np.linspace(0, 1, 101), label=\"Background (validation)\", histtype='step', linewidth=2, density=True)\n",
    "\n",
    "plt.xlabel(\"DNN Response\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDQeYoBWTbOb"
   },
   "source": [
    "## An example of overtraining\n",
    "\n",
    "Let's try to make a more complicated neural network with a much smaller dataset to visualize the effect of overtraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5KjHeBrh5Cc",
    "outputId": "346b0dac-89a8-4143-c34b-881ac548e3d2"
   },
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.Sequential()\n",
    "classifier.add (tf.keras.layers.Dense(128, activation='tanh'))\n",
    "classifier.add (tf.keras.layers.Dense(128, activation='tanh'))\n",
    "classifier.add (tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "classifier.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(3e-3))\n",
    "\n",
    "dfh = df.head(500)\n",
    "df_validation = dfh.sample(100)\n",
    "df_train = dfh[~dfh.index.isin(df_validation.index)]\n",
    "print (f\"Training entries: {len(df_train)}\")\n",
    "print (f\"Validation entries: {len(df_validation)}\")\n",
    "\n",
    "history = classifier.fit(df_train[vars].values, df_train['label'], validation_data=(df_validation[vars], df_validation['label']), batch_size=100, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUpcmPDZToAZ"
   },
   "source": [
    "At some point the loss function on the validation sample starts increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "MmbpROcwjl3d",
    "outputId": "c042e807-0d87-4371-a421-bbeb567677a8"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Binary Crossentropy\")\n",
    "plt.title(\"Simple classifier\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGmuwCmhT0rS"
   },
   "source": [
    "... as a larger fraction of signal events is discarded as background.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "5FSwjdnmjoxF",
    "outputId": "8cbeba17-d17c-4a19-9f02-7873ee11262a"
   },
   "outputs": [],
   "source": [
    "y_train_hat = classifier.predict(df_train[vars].values)\n",
    "extended_validation = df[~df.index.isin(df_train.index)]\n",
    "y_validation_hat = classifier.predict(extended_validation[vars].values, batch_size=10_000)\n",
    "\n",
    "plt.hist(y_train_hat[df_train.label==1], bins = np.linspace(0, 1, 21), label=\"Signal\", histtype='step', linewidth=2, density=True)\n",
    "plt.hist(y_train_hat[df_train.label==0], bins = np.linspace(0, 1, 21), label=\"Background\", histtype='step', linewidth=2, density=True)\n",
    "plt.hist(y_validation_hat[extended_validation.label==1], bins = np.linspace(0, 1, 21), label=\"Signal (validation)\", histtype='step', linewidth=2, density=True)\n",
    "plt.hist(y_validation_hat[extended_validation.label==0], bins = np.linspace(0, 1, 21), label=\"Background (validation)\", histtype='step', linewidth=2, density=True)\n",
    "\n",
    "plt.xlabel(\"DNN Response\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd7ZRFasURmq"
   },
   "source": [
    "## Receiver-Operator-Characteristic (ROC) Curve and Area Under the Curve (AUC)\n",
    "\n",
    "To ease the interpretation of the results we wish to apply a cut to the response of the neural network and focus the rest of our analysis on the fraction of events passing that requirement.\n",
    "\n",
    "Higher statistical power might be obtained by exploiting the whole information instead of simply rejecting candidates that are too unlikely to be signal events, but the increase in statistical power is rarely worth the effort.\n",
    "\n",
    "Now, if our strategy is to apply a cut to the neural network response, we need to compute the fraction of signal and background events passing the selection, as a function of the threshold.\n",
    "\n",
    "We name this fraction \"efficiency\".\n",
    "\n",
    "The complementary fraction (the fraction of events discarded by the selection) is name \"rejection\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 831
    },
    "id": "hqfSEw3PjvD9",
    "outputId": "2d914bf1-e012-4a38-b64d-8f8f316f134d"
   },
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.Sequential()\n",
    "classifier.add (tf.keras.layers.Dense(128, activation='tanh'))\n",
    "classifier.add (tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "classifier.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "\n",
    "dfh = df.head(10_000)\n",
    "df_validation = dfh.sample(2048)\n",
    "df_train = dfh[~dfh.index.isin(df_validation.index)]\n",
    "\n",
    "\n",
    "history = classifier.fit(df_train[vars].values, df_train['label'], validation_data=(df_validation[vars], df_validation['label']), batch_size=1024, epochs=10)\n",
    "\n",
    "y_train_hat = classifier.predict(df_train[vars].values)\n",
    "y_validation_hat = classifier.predict(df_validation[vars].values)\n",
    "\n",
    "plt.hist(y_train_hat[df_train.label==1], bins = np.linspace(0, 1, 101), label=\"Signal\", histtype='step', linewidth=2, density=True)\n",
    "plt.hist(y_train_hat[df_train.label==0], bins = np.linspace(0, 1, 101), label=\"Background\", histtype='step', linewidth=2, density=True)\n",
    "plt.hist(y_validation_hat[df_validation.label==1], bins = np.linspace(0, 1, 101), label=\"Signal (validation)\", histtype='step', linewidth=2, density=True)\n",
    "plt.hist(y_validation_hat[df_validation.label==0], bins = np.linspace(0, 1, 101), label=\"Background (validation)\", histtype='step', linewidth=2, density=True)\n",
    "\n",
    "plt.xlabel(\"DNN Response\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxSmjwq9WXoM"
   },
   "source": [
    "Computing the signal efficiency and background rejection from the distribution of the response is a trivial numpy exercise.\n",
    "\n",
    " * Build the histograms\n",
    " * Obtain the bin contents from the histograms\n",
    " * Compute the cumulative sum of the bin contents (`cumsum`)\n",
    " * Normalized the cumulative sum to make it a cumulative distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "id": "YWSJTzt2sJDk",
    "outputId": "4fdd3958-de93-4510-eb89-d505f9d07474"
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 1, 101)\n",
    "h_sig, _, _ = plt.hist(y_validation_hat[df_validation.label==1], bins=np.linspace(0, 1, 101), label=\"Signal (validation)\", histtype='step', linewidth=2, density=True)\n",
    "h_bkg, _, _ = plt.hist(y_validation_hat[df_validation.label==0], bins=np.linspace(0, 1, 101), label=\"Background (validation)\", histtype='step', linewidth=2, density=True)\n",
    "\n",
    "plt.xlabel(\"DNN Response\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "xAxis = (bins[1:] + bins[:-1])/2\n",
    "plt.plot(xAxis, h_sig)\n",
    "plt.plot(xAxis, h_bkg)\n",
    "\n",
    "plt.xlabel(\"DNN Response\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "0_1c_AaGJU7z",
    "outputId": "753cf771-7425-4287-c117-081eaa4091e9"
   },
   "outputs": [],
   "source": [
    "xAxis = (bins[1:] + bins[:-1])/2\n",
    "plt.plot(xAxis, 1 - np.cumsum(h_sig)/h_sig.sum(), label=\"Signal efficiency\")\n",
    "plt.plot(xAxis, 1 - np.cumsum(h_bkg)/h_bkg.sum(), label=\"Background efficiency\")\n",
    "\n",
    "plt.xlabel(\"Threshold on the DNN Response\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBAUbtAxW5DZ"
   },
   "source": [
    "Signal efficiency and background rejection are usually combined into a unique curve, named Reveiver-Operator-Characteristic (ROC) Curve.\n",
    "\n",
    "The closer to the point (1, 1), the better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "BgOxID_MKlzs",
    "outputId": "9d131eb3-e95e-4dd5-f8b6-a9c84321751c"
   },
   "outputs": [],
   "source": [
    "sig_eff = 1 - np.cumsum(h_sig)/h_sig.sum()\n",
    "bkg_eff = 1 - np.cumsum(h_bkg)/h_bkg.sum()\n",
    "plt.plot(sig_eff, 1 - bkg_eff)\n",
    "plt.plot([1], [1], 'k+')\n",
    "plt.plot([0, 1], [1, 0], 'k--')\n",
    "plt.xlabel(\"Signal efficiency\")\n",
    "plt.ylabel(\"Background rejection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQbuLQNwXNxI"
   },
   "source": [
    "To define a single-number metric for the ability of our algorithm to distinguish between signal and background, we integrate the ROC curve, defining the *Area Under the Curve* (ROC-AUC). The larger the AUC the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M74X8PIoLGwU",
    "outputId": "9d4641dc-7af4-4876-b433-0d28a1a0d362"
   },
   "outputs": [],
   "source": [
    "## Area Under the (ROC) Curve\n",
    "auc = abs(np.trapz(x=sig_eff, y=1-bkg_eff))\n",
    "print (auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3xdM0NQXeMR"
   },
   "source": [
    "Keras ease including the the AUC (and other metrics) directly in the training history, by simply defining it at model-compile time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZeEHEr5Lj-L",
    "outputId": "ed85765b-b73e-48c7-874e-5b82d5d6d90a"
   },
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.Sequential()\n",
    "classifier.add (tf.keras.layers.Dense(128, activation='tanh'))\n",
    "classifier.add (tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "classifier.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(1e-3), metrics=['AUC'])\n",
    "\n",
    "dfh = df.head(10_000)\n",
    "df_validation = dfh.sample(2048)\n",
    "df_train = dfh[~dfh.index.isin(df_validation.index)]\n",
    "\n",
    "\n",
    "history = classifier.fit(df_train[vars].values, df_train['label'], validation_data=(df_validation[vars], df_validation['label']), batch_size=1024, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "hOCMgQh9MbxT",
    "outputId": "8d3cdfa5-fc4a-47af-832a-24557f241ee7"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'], label = \"Validation loss\")\n",
    "plt.plot(history.history['val_auc'], label = \"Validation AUC\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQUno2vsYAPh"
   },
   "source": [
    "## Model selection\n",
    "\n",
    "So far, we have just picked one randomly defined neural network and we studied its capability of classifying signal and background and then we designed a metric, the AUC, to evaluate how good is our DNN to the task.\n",
    "\n",
    "We may wonder if a different choice on the architecture of the neural network would have modified the result. This step is usually named model selection and can be performed in many ways.\n",
    "\n",
    "A possible (but rather expensive) technique is **Grid Search**. We define a set of possible variations to the model and then we test them all.\n",
    "\n",
    "For example we can test models with 1, 3, or 5 layers of 128 nodes, each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vD7QgUKUM3Dk",
    "outputId": "ed316fed-de69-45fb-9c1c-f96184ddb137"
   },
   "outputs": [],
   "source": [
    "def create_dnn(n_layers, n_nodes):\n",
    "  dnn = tf.keras.models.Sequential()\n",
    "  for _ in range(n_layers):\n",
    "    dnn.add (tf.keras.layers.Dense(n_nodes, activation='tanh'))\n",
    "  dnn.add (tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "  dnn.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(1e-3), metrics=['AUC'])\n",
    "\n",
    "  return dnn\n",
    "\n",
    "dfh = df.head(10_000)\n",
    "df_validation = dfh.sample(2048)\n",
    "df_train = dfh[~dfh.index.isin(df_validation.index)]\n",
    "\n",
    "histories = {}\n",
    "for n_layers in 1, 3, 5:\n",
    "  c = create_dnn(n_layers, 128)\n",
    "  histories[n_layers] = c.fit(df_train[vars].values, df_train['label'], validation_data=(df_validation[vars], df_validation['label']), batch_size=1024, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "OptgaVHrNe5b",
    "outputId": "bd7f8b31-2423-42b3-fad1-1fd8bcf85016"
   },
   "outputs": [],
   "source": [
    "n_layers = list(histories.keys())\n",
    "plt.plot(n_layers, [histories[nl].history['val_auc'][-1] for nl in n_layers] )\n",
    "plt.xlabel(\"Number of 128-node layers\")\n",
    "plt.ylabel(\"ROC AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sUL2Aa7Y5nK"
   },
   "source": [
    "If we have more than one parameter to scan, we can nest the loop and test all the possible combinations.\n",
    "\n",
    "Here, for example, we scan over the number of layers and the number nodes per layer.\n",
    "\n",
    "The exercise is complicated by the fact that the initialization of the weights defining the behaviour of layers is random. Hence, the performance obtained by two identical neural networks trained from a different initialization might be significantly different.\n",
    "\n",
    "In general, model selection can be rather expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "x2mflp5HN8xk",
    "outputId": "c66b5b4a-75b3-4b65-8a69-9b70a09584eb"
   },
   "outputs": [],
   "source": [
    "histories = {}\n",
    "from tqdm import tqdm\n",
    "for n_layers in 1, 2, 3:\n",
    "    for n_nodes in tqdm([4, 8, 16, 32, 64]):\n",
    "        c = create_dnn(n_layers, n_nodes)\n",
    "        histories[n_nodes] = c.fit(df_train[vars].values, df_train['label'], validation_data=(df_validation[vars], df_validation['label']), batch_size=1024, epochs=10, verbose=False)\n",
    "\n",
    "        n_nodes = list(histories.keys())\n",
    "    plt.plot(n_nodes, [histories[nn].history['val_auc'][-1] for nn in n_nodes], 'o-', label=f\"{n_layers}\" )\n",
    "plt.xlabel(\"Number nodes of a single-layer NN\")\n",
    "plt.ylabel(\"ROC AUC\")\n",
    "plt.legend(title=\"Number of layers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmFIvX8HZk4q"
   },
   "source": [
    "## Selection of the working point\n",
    "\n",
    "Once we have selected the algorithm with the highest possible AUC, we should decide where the put the threshold defining our selection criterion.\n",
    "\n",
    "The optimal working point depends on the expected number of signal and background events in the final dataset. Such a prediction is usually based on theoretical arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYJCIcmfQ8dL",
    "outputId": "6c6cbdf6-7aba-4ffc-e8c4-7e69be48383e"
   },
   "outputs": [],
   "source": [
    "selected_model = create_dnn(2, 32)\n",
    "history = selected_model.fit(\n",
    "    df_train[vars].values,\n",
    "    df_train['label'],\n",
    "    validation_data=(df_validation[vars], df_validation['label']),\n",
    "    batch_size=1024,\n",
    "    epochs=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "id": "9FpmdnXbSpgc",
    "outputId": "f2a7beef-b5b6-42f9-cdd1-708e9543764d"
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 1, 101)\n",
    "y_validation_hat = classifier.predict(df_validation[vars].values)\n",
    "\n",
    "h_sig, _, _ = plt.hist(y_validation_hat[df_validation.label==1], bins=np.linspace(0, 1, 101), label=\"Signal (validation)\", histtype='step', linewidth=2, density=True)\n",
    "h_bkg, _, _ = plt.hist(y_validation_hat[df_validation.label==0], bins=np.linspace(0, 1, 101), label=\"Background (validation)\", histtype='step', linewidth=2, density=True)\n",
    "\n",
    "plt.show()\n",
    "sig_eff = 1 - np.cumsum(h_sig)/h_sig.sum()\n",
    "bkg_eff = 1 - np.cumsum(h_bkg)/h_bkg.sum()\n",
    "plt.plot(sig_eff, 1 - bkg_eff)\n",
    "plt.plot([1], [1], 'k+')\n",
    "plt.plot([0, 1], [1, 0], 'k--')\n",
    "plt.xlabel(\"Signal efficiency\")\n",
    "plt.ylabel(\"Background rejection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dILnqS9waTFZ"
   },
   "source": [
    "Considering a chosen and trained model, we can try to scan the threshold to study the variation of some metrics describing the \"quality\" of the selected sample.\n",
    "\n",
    "There are several metrics that can be considered depending of the kind of analysis we aim at performing on the selected dataset.\n",
    "\n",
    "A metric that is sometimes useful is the significance\n",
    "$$\n",
    "\\frac{s(t)}{\\sqrt{s(t) + b(t) + 1}}\n",
    "$$\n",
    "where $s$ and $b$ represent the number of signal and background events obtained applying the threshold $t$.\n",
    "We can make the selection efficiency explicit by writing that\n",
    "$$\n",
    "s(t) = S\\, \\varepsilon_S(t)\\\\\n",
    "b(t) = B\\, \\varepsilon_B(t)\n",
    "$$\n",
    "where:\n",
    " * $S$ and $B$ are the numbers of signal and background events in the dataset, **before** applying any additional selection\n",
    " * $\\varepsilon_S(t)$ and $\\varepsilon_B(t)$ are the selection efficiency of the signal and background candidates as defined above.\n",
    "\n",
    "\n",
    "Note that such a metric does not only depend on ratio between signal and background events. Below, we compare the dependency of the metric from the chosen threshold for three different scenarios.\n",
    "\n",
    "The optimal threshold is highlighted with a small circle for each of the three scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "PqBWacckTCjD",
    "outputId": "7678f8ba-0377-4efe-ccb4-bfcd9d78817e"
   },
   "outputs": [],
   "source": [
    "xAxis = (bins[1:] + bins[:-1])/2\n",
    "for S, B in [(0.5, 5), (5, 50), (50, 5000)]:\n",
    "    significance = S * sig_eff / np.sqrt(S * sig_eff + B * bkg_eff + 1)\n",
    "    line, = plt.plot(xAxis, significance/significance.max(), label=f\"S: {S}; B: {B}\")\n",
    "    plt.plot([xAxis[np.argmax(significance)]], [1], 'o',  markersize=5, color=line.get_color())\n",
    "\n",
    "plt.xlabel(\"Threshold on the DNN\")\n",
    "plt.ylabel(\"$S / \\sqrt{S + B + 1}$ (normalized)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYrMuRfZcu_J"
   },
   "source": [
    "## A simple toy study\n",
    "\n",
    "Let's see all that in action.\n",
    "\n",
    "Let's pick one of the scenario assumed above, for example let's say that with our preliminary selection strategy we expect to have a dataset in which 5000 events are purely due to Standard Model physics, while 50 are due to new physics effects. Then we \"create\" such a dataset.\n",
    "\n",
    "1. We randomize the number of signal and background events throwing a random number from a Poissonian distribution\n",
    "2. We apply our trained model to the crafted dataset\n",
    "3. We take the pure Standard Model dataset (background) and we estimate the expectaions under such a \"null hypothesis\" and then we compare what we \"observe\" in the crafted dataset with the expectaions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "s_9wYaZYTp8j",
    "outputId": "17ea0321-1aac-4426-a35b-c23f76865011"
   },
   "outputs": [],
   "source": [
    "bkg = bkg.copy()\n",
    "\n",
    "expected_signal = 50\n",
    "expected_background = 5000\n",
    "\n",
    "toy_sig = sig.sample(np.random.poisson(expected_signal))\n",
    "toy_bkg = bkg.sample(np.random.poisson(expected_background))\n",
    "\n",
    "toy = pd.concat((toy_sig, toy_bkg), axis=0)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "bins = np.linspace(-2, 4, 101)\n",
    "xAxis = (bins[1:] + bins[:-1])/2\n",
    "plt.hist(toy['m2'], bins=bins)\n",
    "bkg_model, _ = np.histogram(bkg['m2'], bins=bins)\n",
    "plt.plot(xAxis, bkg_model * expected_background / len(bkg))\n",
    "\n",
    "plt.xlabel(\"Preprocessed $m_2$ [a.u.]\")\n",
    "plt.ylabel(\"Toy-experiment candidate\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "toy['y_hat'] = selected_model.predict(toy[vars].values)\n",
    "bkg['y_hat'] = selected_model.predict(bkg[vars].values, batch_size=10000)\n",
    "bins = np.linspace(-1, 4, 51)\n",
    "xAxis = (bins[1:] + bins[:-1])/2\n",
    "\n",
    "plt.hist(toy.query('y_hat > 0.7')['m2'], bins=bins, histtype='step', linewidth=2)\n",
    "bkg_model, _ = np.histogram(bkg.query('y_hat > 0.7')['m2'], bins=bins)\n",
    "plt.plot(xAxis, bkg_model * expected_background / len(bkg))\n",
    "plt.xlabel(\"Preprocessed $m_2$ [a.u.]\")\n",
    "plt.ylabel(\"Toy-experiment candidate\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFzSs09ad9x5"
   },
   "source": [
    "The distributions are not very different for signal and background, event after applying the multivariate selection. So we may start with a simple counting experiment, comparing the number of observed and expected events.\n",
    "\n",
    "To make the exercise statistically relevant, we repeat it 100 times assuming 50 signal events (before the selection) and 100 times assuming the pure Standard Model dataset and we compare the excess of events in the two cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "id": "8beXwMTQXHuz",
    "outputId": "cf7a9299-3f0b-46b8-eaa6-3ff263552d84"
   },
   "outputs": [],
   "source": [
    "sig, bkg = sig.copy(), bkg.copy()\n",
    "\n",
    "bkg['y_hat'] = selected_model.predict(bkg[vars].values, batch_size=10000)\n",
    "sig['y_hat'] = selected_model.predict(sig[vars].values, batch_size=10000)\n",
    "\n",
    "def one_toy(expected_signal, expected_background):\n",
    "    toy_sig = sig.sample(np.random.poisson(expected_signal))\n",
    "    toy_bkg = bkg.sample(np.random.poisson(expected_background))\n",
    "\n",
    "    toy = pd.concat((toy_sig, toy_bkg), axis=0)\n",
    "\n",
    "    bins = np.linspace(-1, 4, 51)\n",
    "    xAxis = (bins[1:] + bins[:-1])/2\n",
    "\n",
    "    bkg_model, _ = np.histogram(bkg.query('y_hat > 0.7')['m2'], bins=bins)\n",
    "\n",
    "    return max(0, len(toy.query('y_hat > 0.7')) - (bkg_model.sum() * expected_background / len(bkg)))\n",
    "\n",
    "from tqdm import trange\n",
    "plt.hist([one_toy(0, 5000) for _ in trange(100)], label=\"Background-only\", histtype='step', linewidth=2, hatch='///')\n",
    "plt.hist([one_toy(50, 5000) for _ in trange(100)], label=\"Signal + Background\", histtype='step', linewidth=2, hatch='\\\\\\\\\\\\')\n",
    "plt.xlabel(\"Event excess\")\n",
    "plt.ylabel(\"Pseudo-experiments\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yn3HkgF5er56"
   },
   "source": [
    "# Conclusion\n",
    "In this notebook we went through a first classical application of multivariate methods in High Energy Physics, focussing on the application of a neural network to the enhancement of the signal contribution in a dataset.\n",
    "\n",
    "We discussed model selection and defined the threshold for the selection criterion based on the maximisation of a metric.\n",
    "Finally we built a pseudo-experiment to assess our ability of making a discovery based on the trained model.\n",
    "\n",
    "Each of the steps introduced in this overview would require (at least) one dedicated day of discussion to be covered in some depth. In this introductory lecture we tried to give a conceptual overview of why they are needed and how they are pipelined. More will be discussed during the exercises of the hackathon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7TrGf50gkHr"
   },
   "source": [
    "## Proposed exercises\n",
    "\n",
    "1. Try to break things making some changes to some parameter (number of layers, learning rates, optimizer, number of expected signal and background...) and see the effect on the final result. Try to understand what is happening and why.\n",
    "\n",
    "2. Try to assess the sensitivity of your experiment in case the mass of the actual new-physics state were different from the one used for training.\n",
    "\n",
    "3. Try to train different models for different mass hypotheses. Can you \"interpolate\" models for intermediate mass values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWujT-nIgi4I"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "HEP",
   "language": "python",
   "name": "hep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
